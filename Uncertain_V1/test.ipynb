{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_samples = 5  # 你想要进行的采样次数\n",
    "all_logits = []  # 用于收集所有采样的logits\n",
    "all_entropies = []  # 用于收集所有采样的信息熵\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    standard_nor_distribution = torch.randn(scores_mean.shape).to(scores_mean.device)\n",
    "    scores = scores_mean + torch.mul(standard_nor_distribution, torch.sqrt(scores_cov))\n",
    "    bs, head, seqlen, _ = scores.size()\n",
    "    scores.masked_fill_(mask == 0, -1e32)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    scores = self.attdrop(scores)\n",
    "    v_ = torch.matmul(scores, v)\n",
    "    concat = v_.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
    "    output = self.out_proj(concat)\n",
    "    logits = self.out(torch.cat([output], dim=-1)).squeeze(-1)\n",
    "    all_logits.append(logits)\n",
    "    probs = torch.sigmoid(logits[s >= 0])  # Convert logits to probabilities\n",
    "    entropy = -probs * torch.log(probs) - (1 - probs) * torch.log(1 - probs)  # Binary entropy\n",
    "    all_entropies.append(entropy)\n",
    "\n",
    "# 计算信息熵的平均值\n",
    "mean_entropy = torch.mean(torch.stack(all_entropies), dim=0)\n",
    "\n",
    "# 计算多次预测平均值的信息熵\n",
    "mean_logits = torch.mean(torch.stack(all_logits), dim=0)\n",
    "mean_probs = torch.sigmoid(mean_logits[s >= 0])\n",
    "mean_entropy_of_mean = -mean_probs * torch.log(mean_probs) - (1 - mean_probs) * torch.log(1 - mean_probs)\n",
    "\n",
    "# 计算差值\n",
    "entropy_diff = mean_entropy - mean_entropy_of_mean\n",
    "\n",
    "# 计算加权损失\n",
    "all_losses = []\n",
    "masked_labels = s[s >= 0].float()\n",
    "for logits in all_logits:\n",
    "    masked_logits = logits[s >= 0]\n",
    "    pred_loss = F.binary_cross_entropy_with_logits(masked_logits, masked_labels, reduction='none')\n",
    "    weighted_loss = pred_loss * entropy_diff  # 加权损失\n",
    "    all_losses.append(weighted_loss.mean())  # 对每个样本的加权损失取平均\n",
    "\n",
    "# 累加损失\n",
    "total_loss = sum(all_losses) / num_samples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
